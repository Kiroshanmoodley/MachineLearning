<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Unit 6</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Home</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Back to main</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://github.com/Kiroshanmoodley" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
							<li><a href="https://www.linkedin.com/in/kiroshan-moodley/" class="icon brands fa-linkedin"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Unit 1 learnings -->
							<section class="post">
								<header class="major">
									<span class="date">12 April 2022 ~ 18 April 2022</span>
									<h2>Unit 6 learnings</h2>
								</header>
							
							<!-- Section 1 - Unit Learnings -->
							<p>Hi  colleagues<p>
							<p>Unit 6 Introduced practical lessons introducing the WEKA tool. The class was introduced to loading datasets, converting them into .arff format files, and testing various algorithms on the dataset.<br /><br />
							Collaborative learning discussion 2 also got underway with my topic being the discussion of two machine learning algorithms and the context ion which they can be used. During the discussion many of my peers
							mentioned decision trees as a supervised training method in which decision made are easy to understand, as the tree is fairly simple to visualize with small datasets. Many of my peer posts such as (Dewaji, 2022), including my own
							had also made mention of the efficiency of decision tree based algorithms.<br /><br />
							Many methods of unsupervised learning methods were mentioned, notably (Kanakavelu, 2022) who elaborated on the k-means clustering algorithm, with selection of hyperparameter tuning such as k, and
							Lukashevich, 2022) who noted the "Black box" nature deep neural networks can have, which make it difficult to explain predictions.<br /><br />
							
							<h2>My initial post:<br /><br /></h2>
							<p>Decision trees provide a simple supervised learning method of data classification (Bell, 2020) and enables ease in visualising instance attribute nodes at the root of the tree, down to the various classes (Wikipedia, 2022). Another positive attribute for the use of decision trees is that do not require high end processing power and handle large datasets well (Bell, 2020).<br /><br />
							Decision trees however have a few drawbacks. Over fitting can occur if all training data is used to train the system, which then memorises the noise and fails to interrogate important patterns (Kumar, 2021). It is for this reason various algorithms (such as C4.5, CART, OC1) use a technique called pruning, where the algorithm allows the tree to grow to maximum size, then prunes the tree. In C4.5, this is done by replacing branches with leaves until a reduction of predicted error rate is seen, and with CART and OC1 algorithms for example, using only a portion of the training sample to prune the tree (Podgorelec, et al., 2002).<br /><br />
							Decision trees are well suited for data which is labelled, and have recurring, well defined problems which must be solved, such as spam detection, weather forecasting, or medical diagnosis through result data (Delua, 2021). In a study by (Nahar & Ara, 2018) on liver disease prediction, decision tree algorithms were chosen as they had better accuracy in results over other algorithms and were able to handle large datasets more easily.<br /><br />
							Association rules learning method is an unsupervised learning method designed to find pertinent relationships among elements of data (Bell, 2020). Usually, unsupervised methods are applied to very large datasets, for instance, (Basset, et al., 2018) show some types input data, stating that Googles receives 1 billion queries per day, and YouTube counts up to 4 billion views per day of data. This is more data than a human can easily process to gain insight.<br /><br />
							Some drawbacks of association rules are algorithmic performance (which will affect computing efficiency), and generation of large output sets as many item-sets may be non-frequent, but add load to process and eliminate them. New methods already exist to ensure non interesting datasets are pruned, such as MONPNAR which uses a pareto based algorithm to prune rules, or MDS-H which employs a grouping mechanism to prevent non frequent item-sets (Ghafari & Tjortjis, 2018).<br /><br />
							Much use of the association rules machine learning method is found in customer purchasing decisions, website data mining, and mining  learning management systems (LMS), to find patterns and trends (Son, et al., 2018). <br /><br />
							In conclusion, unsupervised learning uses machine learning algorithms which cluster and analyse unlabelled datasets to interpret data where correlations are otherwise not yet known. Supervised learning predicts outcomes based on labelled datasets which have been empirically gathered to predict outcomes for new input datasets. Please add further techniques or methods which can also give increased productivity of machine learning systems.<br /><br />
							References:<br /><br />
							Basset, M. . A., Mohamed, M., Smarandache, F. & Chang, V., 2018. Neutrosophic Association Rule Mining Algorithm for Big Data Analysis. <i>Symmetry,</i> 10(4), p. 106.<br /><br />
							Bell, J., 2020. <i>Machine Learning: Hands-On for Developers and Technical Professionals.</i> 2nd ed. Chichester: Wiley.<br /><br />
							Delua, J., 2021. <i>Unsupervised Learning: Whatâ€™s the Difference?.</i> [Online] Available at: <u>https://www.ibm.com/cloud/blog/supervised-vs-unsupervised-learning</u> [Accessed 10 04 2022].<br /><br />
							Ghafari, S. M. & Tjortjis, C., 2018. A survey on association rules mining using heuristics. <i>Data Mining and Knowledge Discovery,</i> 9(4), pp. 1-29.<br /><br />
							Kumar, S., 2021. <i>3 Techniques to Avoid Overfitting of Decision Trees.</i> [Online] Available at: <u>https://towardsdatascience.com/3-techniques-to-avoid-overfitting-of-decision-trees-1e7d3d985a09</u> [Accessed 10 04 2022].<br /><br />
							Nahar, N. & Ara, F., 2018. Liver Disease Prediction by Using Different Decision Tree Techniques. <i>International Journal of Data Mining & Knowledge Management Process,</i> 8(2), pp. 01-09.<br /><br />
							Podgorelec, V., Kokol, P., Stiglic, B. & Rozman, I., 2002. Decision trees: an overview and their use in medicine. <i>Journal of Medical Systems,</i> 26(5), pp. 445-463.<br /><br /><p>
							Son, L. H. et al., 2018. ARM-AMO: An Efficient Association Rule Mining Algorithm Based on Animal Migration Optimization. <i>Knowledge-Based Systems,</i> Volume 154, pp. 68-80.<br /><br /><p>
							Wikipedia, 2022. <i>Decision tree learning.</i> [Online] Available at: <u>https://en.wikipedia.org/wiki/Decision_tree_learning#:~:text=A%20decision%20tree%20is%20a,classification%20is%20called%20a%20class.</u> [Accessed 10 04 2022].<br /><br /><p>

							<p><span class="image left"><img src="images/WEKAWorkbench.jpg" alt="" /></span>The WEKA workbench, (Frank E, et al., 2016) presented an excellent practical introduction to WEKA, and would go on in later units to expand in later chapters. Chapter 1 focussed on what the user can do with WEKA, and how the package management system works.<br /><br /><br /><br /><br /><br /></p>
							</section>
					</div>

				<!-- Footer -->
					<footer id="footer">
						<section>
							<form method="post" action="#">
								<div class="fields">
									<div class="field">
										<label for="name">Name</label>
										<input type="text" name="name" id="name" />
									</div>
									<div class="field">
										<label for="email">Email</label>
										<input type="text" name="email" id="email" />
									</div>
									<div class="field">
										<label for="message">Message</label>
										<textarea name="message" id="message" rows="3"></textarea>
									</div>
								</div>
								<ul class="actions">
									<li><input type="submit" value="Send Message" /></li>
								</ul>
							</form>
						</section>
						<section class="split contact">
							<section class="alt">
								<h3>Address</h3>
								<p>Turnberry Office Park<br />
								Bryanston</p>
							</section>
							<section>
								<h3>Email</h3>
								<p><a href="#">kiroshanmoodley@yahoo.com</a></p>
							</section>
							<section>
								<h3>Social</h3>
								<ul class="icons alt">
								<li><a href="https://github.com/Kiroshanmoodley" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
								<li><a href="https://www.linkedin.com/in/kiroshan-moodley/" class="icon brands fa-linkedin"><span class="label">GitHub</span></a></li>
								</ul>
							</section>
						</section>
					</footer>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
